<!DOCTYPE HTML>
<!--
	Strata by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Samsara Counts</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<!--[if lte IE 8]><script src="assets/js/ie/html5shiv.js"></script><![endif]-->
		<link rel="stylesheet" href="assets/css/main.css" />
		<!--[if lte IE 8]><link rel="stylesheet" href="assets/css/ie8.css" /><![endif]-->
	</head>
	<body id="top">
<!-- Header -->
			<header id="header">
				<div class="inner">
					<a href="http://samsaranc.github.io" class="image avatar"><img src="images/avatar.jpg" alt="" /></a>
					<h1><strong></a><a href="http://samsaranc.github.io">Samsara Counts</a></strong></br>
					<a href="http://cs.seas.gwu.edu">Computer Science</a> + <a href="http://math.columbian.gwu.edu">Mathematics</a><br/> student and researcher
					attending <a href="http://www.gwu.edu">the George Washington University</a>. Previously at UMD's <a href="http://www.cs.umd.edu/projects/reucaar/">REU CAAR</a>
				    <h3><a href="pubs.html">Publications</a></h3>
					<h3><a href="portfolio.html">Portfolio</a></h3>
                    <h3><a href="cv_index.html">Computer Vision</a></h3>
					<h3><a href="http://undecidabi1ity.tumblr.com/">Academic Blog</a></h3>
				</div>
			</header>

		<!-- Main -->
			<div id="main">
				<section>
							<h1><a href="http://robertpless.com/classes/ComputerVision/FinalProject/index.html">Computer Vision Final Project </a>: Recognizing Images with Deep Learning </h1>
							<p>
							<h3>Introduction:</h3>					
								<h3>Sample output</h3>
								<a href="images/fulls/CVproana.png" class="image fit thumb"><img src="images/fulls/CVproana.png" alt="Computer Vision Proana tumblr dataset featuring images of individuals with Eating Disorders and images that fall under the hashtag #selfie or #ootd" /></a>
							
							Eating disorders (ED) are pervasive and do not discriminate based on race, religion, gender, or socioeconomic status. Comorbidities include anxiety, depression, substance abuse, self-injurious behaviors, and history of trauma. ED are often a lifelong struggle, with approximately 2/3 of patients never achieving a full and sustained remission.</br>
							Exposure to media expressing “the thin ideal” can be triggering to individuals with ED as well as those at risk for developing them. Social media is rife with these triggers. Concurrent with the rise of social media, individuals with ED have created communities in which they support one another in the dangerous pursuit of this illness' goal: to be “thin enough.” Websites promoting anorexia (pro-ana) and ED as lifestyle choices valorize acting on ED symptoms. Such sites teach those suffering or at risk from ED how to act on the illness and support them in doing so, putting
							them at risk for severe health complications.</br>

							The impact of images in this community far exceeds that of other communities surrounding
							physical and mental health issues. Therefore, it is essential that clinicians and family members be able to identify websites containing images associated with the promotion of ED to prevent exposure to these triggers. This research aims to automatically detect such triggering material, with the ultimate goal of designing parental and clinical controls.</br> 

							We report on a proof of concept, machine learning approach to identify pro-ana content, trained on example data from online social media searches. The training data was chosen to compare pro-ana content with other content similar in demographics and photographic style, composed of the hashtag-based categories #proana, #selfie, #ootd, and #greek.
							We randomly chose 20% of these images as test data and train the Resnet Deep Learning neural network to classify the remaining images. On test data this gives 81% classification accuracy—a significant improvement over chance (25%). These proof of concept results suggest that it is feasible to automatically detect social media sources with triggering material, informing the creation of tools that can assist clinicians and family members to improve health outcomes.</br>
							We used the classifier to make a web application that assesses how pro-ana a social media
							user’s content is. The tool, designed for clinicians, allows them to enter a social media username
							and then gives an analysis of that user’s online presence, classifying its content. The tool also
							displays a hashtag similarity map showing trending hashtags closely related to #proana.

						</p>

							<h3>Baseline (Naive) Implementation:</h3>
							<p>To align the RGB images, I decided to use the Normalized Cross Correlation metric as a baseline, because I noticed that it outperfomed sum of squared differences (SSD) on a small sample of test images.<br>

							My program divides the image into 3 equal parts, aligns the second and the third parts (G and R) to the first (B). 
							For each image, I record the displacement vector that was used to align the parts. 

							<h3>Sample Single-Scale Processing Results</h3>
							<table style="width:100%">
							  <tr>
							  	<td><h4>NCC final image</h4><img src= "images/cv-18/p1/c_00106v.jpg" alt="color image"></img></td>
							   <!--  <td><h4>Gradient final image</h4><img src= "images/cv-18/p1/c_00106v.jpg" alt="color image"></img></td> -->
							    <td><h4>G</h4><img src= "images/cv-18/p1/g_00106v.jpg" alt="green image"></img></td> 
							    <td><h4>R</h4><img src= "images/cv-18/p1/r_00106v.jpg" alt="red image"></img></td>
							    <td><h4>B</h4><img src= "images/cv-18/p1/b_00106v.jpg" alt="blue image"></img></td>
							  </tr>
							</table>

							<p>
							However, since exhaustive search becomes expensive if the displacement search range/image resolution are too large, I implemented a second method for the high-res images: a multi-scale aligning algorithm that searches over a user-specified window of displacements. <br>
							</p>

							<h3>Image Pyramids</h3>
							<p>

							To handle alignment for larger images, I used image pyramids to implement a faster search algorithm. Given two images, my image pyramid alignment algorithm recursively resizes images by factors of 2 at multiple scales, averages them by taking a uniform average of each, and respectively aligns them from the coarsest scale to the finest scale (largest image).<br></p>
							
						 <h3>Image Pyramid Sample Results (from high res. scans)</h3>
							  <table >
							  <tr> 
							   
							   <td><img src= "images/cv-18/p1/train.jpg" alt="color image"></img></td>
							   <td><img src= "images/cv-18/p1/01047a.jpg" alt="color image"></img></td>
							   <td><img src= "images/cv-18/p1/00882a.jpg" alt="color image"></img></td>

							  </tr>
							</table>
							<h3>Bells and Whistles: Cropping with Edge Detection</h3>
							<p>

							Our overall goal is to reduce boundary noise in the dataset; thus, we need to crop the colorful, shifted borders. Hence, I used a combination of edge detection and averages to compute the cropping dimensions for each image. After generating the final color image by the alignment algorithms above, I use the following algorithm to crop the final image based on those computed dimensions. 

							<h3>Cropping Algorithm</h3>
							<h4><b>Input:</b> channel image I</h4>
							<ul>
								<li>Run edge detection on I to create an edge response map </li>

									<li> average the edge response map horizontally to make vector V_h with length = image's height</li>
										<li> calculate a threshold equal to 2 standard deviations above the mean over all values in V_h</li>
		 
										<li> sequentially search the first tenth of values in V from right to left, getting the first value that's higher than the threshold</li>

										<li> sequential search from left to right over the last tenth of V_h </li>

										<li> Save indices as the top and bottom cropping bounds</li>

									<li> Do similar search with V_v, vector generated by vertical average of edge response map to get left and right cropping bounds </li>
							</ul>


							<h3>Cropping and Edge Detection</h3>
							<table >
							  <tr>
							  	<td>Original R<img src= "images/cv-18/p1/g_00907v.jpg" alt="color image" ></img></td>
							  	<td>Edge Detection Map<img src= "images/cv-18/p1/edge_detect_map.png" alt="edge_detect_map" style="width:99%"></img></td>
							  	<td>Cropped R<img src= "images/cv-18/p1/g_00907_CROP.jpg" alt="red image" ></img></td>
							  </tr>

							</table>

							<h3>Sample Cropping Results</h3>
							<table style="width:100%">
							  <tr>
							  	<td><h4>Before</h4><img src= "images/cv-18/p1/c_00757v.jpg" alt="image before crop"></img></td>
							    <td><h4>After</h4><img src= "images/cv-18/p1/c_00757v_CROP.jpg" alt="color image"></img></td>
							 
							</tr>							  
							<tr>
							  	<td><h4>Before</h4><img src= "images/cv-18/p1/c_00888v.jpg" alt="image before crop"></img></td>
							  	<td><h4>After</h4><img src= "images/cv-18/p1/c_00888v_CROP.jpg" alt="red image"></img></td>
							  </tr>
							  </table>

							 <h2>(More) Sample Results</h2>
							<table style="width:100%">
							<tr>
							  	<td><img src= "images/cv-18/p1/c_00889v_CROP.jpg" alt="red image"></img></td>
							  	<td><img src= "images/cv-18/p1/c_00911v_CROP.jpg" alt="red image"></img></td>
							  

							  </tr>
							  <tr>
							  	<td><img src= "images/cv-18/p1/c_00907v_CROP.jpg" alt="blue image"></img></td>
							  	<td><img src= "images/cv-18/p1/c_01031v_CROP.jpg" alt="red image"></img></td>

							  </tr>
							  </table>


			    </section>
			</div>
<!-- Footer -->
			<footer id="footer">
				<div class="inner">
					<ul class="icons">
						<li><a href="https://github.com/samsaranc" class="icon fa-github"><span class="label">Github</span></a></li>
						<li> <a href="https://limeconnect-csm.symplicity.com/profiles/samsara.counts2">Lime Network</a></li>
						<li><a href="https://www.linkedin.com/in/samsaranc/" class="icon fa-linkedin"><span class="label">LinkedIn</span></a></li>
						<li><a href="https://twitter.com/samsaranc" class="icon fa-twitter"><span class="label">Twitter</span></a></li>
						<li><a href="mailto:samsaranc@gmail.com" class="icon fa-envelope-o"><span class="label">Email</span></a></li>
					</ul>
					<ul class="copyright">
						<li>Last updated: September 2017</li>
						<li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
						<li>Background: <a href="https://www.lansbergen.net/wp/solargraphy/">Jan Koeman Kloetinge</a> </li>
					</ul>

				</div>
			</footer>


		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.poptrox.min.js"></script>
			<script src="assets/js/skel.min.js"></script>
			<script src="assets/js/util.js"></script>
			<!--[if lte IE 8]><script src="assets/js/ie/respond.min.js"></script><![endif]-->
			<script src="assets/js/main.js"></script>

	</body>
</html>
